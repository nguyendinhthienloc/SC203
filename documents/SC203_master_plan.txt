SC203 Research To-Do Master Plan
=================================

This document contains the full, comprehensive, structured, actionable roadmap for your research project.

---------------------------------------
PHASE 1 — Core Pipeline Validation (LOCAL)
---------------------------------------

1. Validate the nominalization pipeline on a small dataset (20–50 samples).
2. Fix any errors in:
   - ingestion
   - cleaning
   - POS tagging
   - noun/nominalization counts
   - ratio calculations
3. Verify that all CLI scripts work:
   - analyze_nominalization.py
4. Confirm all outputs generate correctly:
   - augmented CSV
   - figures (boxplots, CI plots)
   - statistical tables
5. Profile spaCy speed and optimize:
   - disable unnecessary pipeline components
   - batch texts
   - test GPU if available
6. Check export integrity:
   - does cleaned data save?
   - do plots save?
   - do tables save?

---------------------------------------
PHASE 2 — Expand Linguistic Features (LOCAL)
---------------------------------------

Add and validate additional features already supported in the repo:

1. Lexical metrics:
   - TTR
   - average sentence length
   - average word length

2. POS proportions:
   - noun %
   - verb %
   - adjective %

3. Collocations:
   - bigram PMI
   - frequency-based filtering

4. Keywords:
   - log-odds with Haldane–Anscombe correction

5. Run stats on all features:
   - t-test
   - Mann–Whitney
   - Cohen's d
   - confidence intervals

6. Generate combined figures:
   - multi-panel plots
   - summary tables

---------------------------------------
PHASE 3 — Expansion to Mid-Size Datasets (CLOUD: COLAB)
---------------------------------------

1. Migrate the repository to Colab:
   - clone repo
   - install requirements
   - download spaCy model

2. Upload mid-size datasets:
   - 100 human essays
   - 100 AI essays
   - 2–3 topical domains

3. Run full pipeline:
   - ingestion → cleaning → features → stats → plots → tables

4. Fix cloud-only issues:
   - path resolution
   - storage handling
   - long-running cell behavior

5. Save outputs to a Google Drive folder:
   - figures/
   - tables/
   - processed CSV

6. Validate cross-domain consistency:
   - compare health vs education vs tech

---------------------------------------
PHASE 4 — Large-Scale Experiments (CLOUD: KAGGLE)
---------------------------------------

Move to Kaggle for:
- large datasets (500–10,000 texts)
- long runs (up to 9 hours)
- GPU-tagged processing

Tasks:

1. Upload your repo as a Kaggle dataset.
2. Create a Kaggle notebook:
   - install requirements
   - run pipeline end-to-end
3. Add multiple AI models:
   - GPT-3.5
   - GPT-4o
   - Claude
   - Llama-3 70B
4. Add cross-domain datasets:
   - general essays
   - academic writing
   - opinion pieces
   - news
5. Evaluate robustness:
   - cross-model
   - cross-topic
   - mixed prompts
6. Compute final metrics:
   - distribution differences
   - effect sizes
   - classifier-friendly features

---------------------------------------
PHASE 5 — Paper Preparation (ALL RESULTS READY)
---------------------------------------

1. Write Methods section:
   - datasets
   - pipeline architecture
   - cleaning
   - POS/nominalization logic
   - feature extraction
   - stats framework

2. Write Results section:
   - boxplots for each feature
   - statistical significance tables
   - effect size interpretation
   - cross-domain patterns

3. Write Discussion:
   - compare with IRAL baseline
   - compare with GECSCORE baseline
   - highlight novelty of nominalization ratio

4. Write Limitations:
   - dataset size
   - model bias
   - domain mismatch

5. Write Conclusion:
   - whether nominalization ratio can detect AI writing
   - how to integrate with other linguistic features

6. Prepare appendix:
   - all tables
   - command-line instructions
   - additional figures

---------------------------------------
PHASE 6 — Optional Extensions
---------------------------------------

1. Add sentence-level complexity metrics.
2. Add dependency parse features.
3. Add a simple ML classifier using extracted features.
4. Run ablation studies.
5. Create a web-based demo.

---------------------------------------
END OF MASTER PLAN
---------------------------------------
